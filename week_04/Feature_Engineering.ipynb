{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/RiskModellingResearch/DeepLearning_Autumn22"
      ],
      "metadata": {
        "id": "E-43cqQvG3l-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics -- quiet"
      ],
      "metadata": {
        "id": "pt2-WM7nHD_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2EcBXuxShozJ"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "import torch\n",
        "\n",
        "print(torch.__version__)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset, Sampler\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bHFeh9lGhozL"
      },
      "outputs": [],
      "source": [
        "INPUT_SIZE = 36\n",
        "HIDDEN_SIZE = 25\n",
        "OUTPUT_SIZE = 5\n",
        "LEARNING_RATE = 1e-2\n",
        "EPOCHS = 400\n",
        "BATCH_SIZE = 256\n",
        "EMBEDDING_SIZE = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "MPZo6DcPhozM"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    # Конструктор, где считаем датасет\n",
        "    def __init__(self):\n",
        "        X = pd.read_csv('./DeepLearning_Autumn22/week_04/data/X_cat.csv', sep='\\t', index_col=0)\n",
        "        target = pd.read_csv('./DeepLearning_Autumn22/week_04/data/y_cat.csv', sep='\\t', index_col=0, names=['status'])  # header=-1,\n",
        "\n",
        "        weekday_columns = ['Weekday_0', 'Weekday_1', 'Weekday_2',\n",
        "                           'Weekday_3', 'Weekday_4', 'Weekday_5', 'Weekday_6']\n",
        "        weekdays = np.argmax(X[weekday_columns].values, axis=1)\n",
        "\n",
        "        X.drop(weekday_columns, axis=1, inplace=True)\n",
        "\n",
        "        \n",
        "        X['Weekday_cos'] = np.cos((2 * np.pi / 7.) * weekdays)\n",
        "        X['Weekday_sin'] = np.sin((2 * np.pi / 7.) * weekdays)\n",
        "\n",
        "        X['Hour_cos'] = np.cos((2 * np.pi / 24.) * X['Hour'].values)\n",
        "        X['Hour_sin'] = np.sin((2 * np.pi / 24.) * X['Hour'].values)\n",
        "\n",
        "        X['Month_cos'] = np.cos((2 * np.pi / 12.) * X['Month'].values)\n",
        "        X['Month_sin'] = np.sin((2 * np.pi / 12.) * X['Month'].values)\n",
        "\n",
        "        X['Gender'] = np.argmax(X[['Sex_Female', 'Sex_Male', 'Sex_Unknown']].values, axis=1)\n",
        "\n",
        "        X.drop(['Sex_Female', 'Sex_Male', 'Sex_Unknown'], axis=1, inplace=True)\n",
        "\n",
        "        print(X.shape)\n",
        "        print(X.head())\n",
        "\n",
        "        target = target.iloc[:, :].values\n",
        "        target[target == 'Died'] = 'Euthanasia'\n",
        "\n",
        "        le = LabelEncoder()\n",
        "        self.y = le.fit_transform(target)\n",
        "\n",
        "        self.X = X.values\n",
        "\n",
        "        self.columns = X.columns.values\n",
        "\n",
        "        self.embedding_column = 'Gender'\n",
        "        self.nrof_emb_categories = 3\n",
        "        self.numeric_columns = ['IsDog', 'Age', 'HasName', 'NameLength', 'NameFreq', 'MixColor', 'ColorFreqAsIs',\n",
        "                                'ColorFreqBase', 'TabbyColor', 'MixBreed', 'Domestic', 'Shorthair', 'Longhair',\n",
        "                                'Year', 'Day',  'Breed_Chihuahua Shorthair Mix', 'Breed_Domestic Medium Hair Mix',\n",
        "                                'Breed_Domestic Shorthair Mix', 'Breed_German Shepherd Mix', 'Breed_Labrador Retriever Mix',\n",
        "                                 'Breed_Pit Bull Mix', 'Breed_Rare',\n",
        "                                'SexStatus_Flawed', 'SexStatus_Intact', 'SexStatus_Unknown',\n",
        "                                'Weekday_cos', 'Weekday_sin', 'Hour_cos', 'Hour_sin',\n",
        "                                'Month_cos', 'Month_sin']\n",
        "\n",
        "        return\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    # Переопределяем метод,\n",
        "    # который достает по индексу наблюдение из датасет\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        row = self.X[idx, :]\n",
        "\n",
        "        row = {col: torch.tensor(row[i]) for i, col in enumerate(self.columns)}\n",
        "\n",
        "        return row, self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "H-BybCiNhozN"
      },
      "outputs": [],
      "source": [
        "class MLPNet(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, nrof_cat, emb_dim,\n",
        "                 emb_columns, numeric_columns):\n",
        "        super(MLPNet, self).__init__()\n",
        "        self.emb_columns = emb_columns\n",
        "        self.numeric_columns = numeric_columns\n",
        "\n",
        "        self.emb_layer = torch.nn.Embedding(nrof_cat, emb_dim)\n",
        "\n",
        "        self.feature_bn = torch.nn.BatchNorm1d(input_size)\n",
        "\n",
        "        self.linear1 = torch.nn.Linear(input_size, hidden_size)\n",
        "        self.linear1.apply(self.init_weights)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(hidden_size)\n",
        "\n",
        "        self.linear2 = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear2.apply(self.init_weights)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(hidden_size)\n",
        "\n",
        "        self.linear3 = torch.nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def init_weights(self, m):\n",
        "        if type(m) == nn.Linear:\n",
        "            torch.nn.init.xavier_uniform(m.weight)\n",
        "            # m.bias.data.fill_(0.001)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb_output = self.emb_layer(torch.tensor(x[self.emb_columns], dtype=torch.int64))\n",
        "        numeric_feats = torch.tensor(pd.DataFrame(x)[self.numeric_columns].values, dtype=torch.float32)\n",
        "\n",
        "        concat_input = torch.cat([numeric_feats, emb_output], dim=1)\n",
        "        output = self.feature_bn(concat_input)\n",
        "\n",
        "        output = self.linear1(output)\n",
        "        output = self.bn1(output)\n",
        "        output = torch.relu(output)\n",
        "\n",
        "        output = self.linear2(output)\n",
        "        output = self.bn2(output)\n",
        "        output = torch.relu(output)\n",
        "\n",
        "        output = self.linear3(output)\n",
        "        predictions = torch.softmax(output, dim=1)\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AK1EMAHLhozO"
      },
      "outputs": [],
      "source": [
        "def run_train(model, train_loader):\n",
        "    step = 0\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "\n",
        "        for features, label in train_loader:\n",
        "            # Reset gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(features)\n",
        "            # Calculate error and backpropagate\n",
        "            loss = criterion(output, label)\n",
        "            loss.backward()\n",
        "            acc = accuracy(output, label).item()\n",
        "\n",
        "            # Update weights with gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            step += 1\n",
        "\n",
        "            if step % 100 == 0:\n",
        "                print('EPOCH %d STEP %d : train_loss: %f train_acc: %f' %\n",
        "                      (epoch, step, loss.item(), acc))\n",
        "\n",
        "\n",
        "    return step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bkPPQLw9hozP"
      },
      "outputs": [],
      "source": [
        "animal_dataset = CustomDataset()\n",
        "train_loader = data_utils.DataLoader(dataset=animal_dataset,\n",
        "                                     batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "model = MLPNet(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE, animal_dataset.nrof_emb_categories,\n",
        "               EMBEDDING_SIZE,\n",
        "               animal_dataset.embedding_column, animal_dataset.numeric_columns)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "accuracy = Accuracy()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "scrolled": true,
        "id": "nuTe8w-GhozP"
      },
      "outputs": [],
      "source": [
        "step = run_train(model, train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "F4iF0bKQhozQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
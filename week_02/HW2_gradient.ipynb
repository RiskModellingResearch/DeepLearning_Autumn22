{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1u0erYV7_lr"
      },
      "source": [
        "# 50 оттенков градиентного спуска \n",
        "\n",
        "В этом задании вам предстоит реализовать линейный классификатор и натренировать его, используя различные модификации градинетного спуска. Тетрадка позаимствована с [шадовского курса по нейронкам.](https://github.com/yandexdataschool/Practical_DL/blob/master/week01_backprop/adapdive_sgd/adaptive_sgd.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeyBrbUK7_lt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSDX4k9g7_lu"
      },
      "source": [
        "## Генерация выборки\n",
        "\n",
        "Для наших целей будем использовать искуственно сгенерированные данные."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ-KTK_C7_lv"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets, preprocessing\n",
        "\n",
        "# keep random_state=42 for deterministic results\n",
        "(X, y) = datasets.make_circles(n_samples=1024, shuffle=True, noise=0.2, factor=0.4, random_state=42)\n",
        "ind = np.logical_or(y == 1, X[:, 1] > X[:, 0] - 0.5)\n",
        "X = X[ind, :]\n",
        "m = np.array([[1, 1], [-2, 1]])\n",
        "X = preprocessing.scale(X)\n",
        "y = y[ind]\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired, s=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLx6ZurA7_lw"
      },
      "source": [
        "### [1] Варка фичей\n",
        "\n",
        "Как вы можете заметить, данные не являются линейно разделимыми. Нам придётся добавить в обучающую выборку новые фичи либо использовать нелинейные модели. Предположим, что разделяющая поверхность имеет вид окружности. Добавьте в матрицу признаков дополнительные колонки $x_1^2$, $x_2^2$ и $x_1 \\cdot x_2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gy-bGbJ47_lw"
      },
      "outputs": [],
      "source": [
        "def expand(X):\n",
        "    \"\"\"\n",
        "    Добавляет квадратичные фичи. \n",
        "    Для каждой строки матрицы находит строку \n",
        "    [feature0, feature1, feature0^2, feature1^2, feature0*feature1, 1]\n",
        "    \n",
        "    :param X: матрица фичей, shape [n_samples,2]\n",
        "    :returns: расширенная матрица фичей, shape [n_samples,6]\n",
        "    \"\"\"\n",
        "\n",
        "    # ваш код здесь\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAP_Az-N7_lx"
      },
      "source": [
        "### [3] Логистическая регрессия \n",
        "\n",
        "Для классификации будем использовать логистическую регрессию. \n",
        "\n",
        "$$ a(x; w) = \\langle w, x \\rangle $$\n",
        "$$ P( y=1 \\; \\big| \\; x, \\, w) = \\dfrac{1}{1 + \\exp(- \\langle w, x \\rangle)} = \\sigma(\\langle w, x \\rangle)$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ikWgpKn7_lx"
      },
      "outputs": [],
      "source": [
        "def probability(X, w):\n",
        "    \"\"\"\n",
        "    Принимает на вход матрицу фичей и вектор весов\n",
        "    Возвращает предсказание вероятность того, что y = 1 при фиксированных x, P(y=1|x)\n",
        "    \n",
        "    :param X: расширенная матрица фичей [n_samples,6] (expanded)\n",
        "    :param w: вектор весов [6]\n",
        "    :returns: вектор вероятностей\n",
        "    \"\"\"\n",
        "\n",
        "    # ваш код здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf7JEDUo7_ly"
      },
      "source": [
        "Для логистической регрессии оптимальный параметр находится минимизацией кросс-энтропии: \n",
        "\n",
        "$$ L(w) =  - {1 \\over \\ell} \\sum_{i=1}^\\ell \\left[ {y_i \\cdot log P(y_i = 1 \\, | \\, x_i,w) + (1-y_i) \\cdot log (1-P(y_i = 1 \\, | \\, x_i,w))}\\right] $$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vu0FP6AM7_ly"
      },
      "outputs": [],
      "source": [
        "def compute_loss(X, y, w):\n",
        "    \"\"\"\n",
        "    Принимает на вход матрицу весов, вектор ответов и вектор весов.\n",
        "    Выдаёт на выход значение функции потерь, расчитанное по формуле выше.\n",
        "    \"\"\"\n",
        "\n",
        "    # ваш код здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYRbj_jw7_lz"
      },
      "source": [
        "Мы будем обучать модель методом градиентного спуска. Для этого нам придётся вычислить градиент функции потерь, представленной выше. Возьмите листочек, ручку и в бой! \n",
        "\n",
        "$$ \\nabla_w L = ...$$\n",
        "\n",
        "Тут обойдёмся даже без матричного дифириенцирования. А вот в следущий раз его не миновать..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRpbR5pW7_lz"
      },
      "outputs": [],
      "source": [
        "def compute_grad(X, y, w):\n",
        "    \"\"\"\n",
        "    Нахоит значение градиента.\n",
        "    \"\"\"\n",
        "\n",
        "    # ваш код здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UsPjUFF7_l0"
      },
      "source": [
        "Функция ниже предназначена для визуализации процесса обучения. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_2_b9ZI7_l0"
      },
      "outputs": [],
      "source": [
        "from IPython import display\n",
        "\n",
        "h = 0.01\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "\n",
        "def visualize(X, y, w, history):\n",
        "    \"\"\"С помощью магии matplolib выдаёт красоты результатов классификации\"\"\"\n",
        "    Z = probability(expand(np.c_[xx.ravel(), yy.ravel()]), w)\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
        "    plt.xlim(xx.min(), xx.max())\n",
        "    plt.ylim(yy.min(), yy.max())\n",
        "    \n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history)\n",
        "    plt.grid()\n",
        "    ymin, ymax = plt.ylim()\n",
        "    plt.ylim(0, ymax)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkERRU_N7_l0"
      },
      "outputs": [],
      "source": [
        "# убедитесь, что у вас она работает, запустив код ниже \n",
        "# (он отработает если вы верно реализовали expend и probability)\n",
        "dummy_weights = np.linspace(-1, 1, 6)\n",
        "visualize(X, y, dummy_weights, [0.5, 0.5, 0.25])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2kWIugW7_l1"
      },
      "source": [
        "## Обучение\n",
        "\n",
        "Пришло время обучить нашу модель. Для этого вам придётся дописать кусочки функций ниже. Обязательно попробуйте поменять гиперпараметры (размер батча и скорость обучения) и посмотреть как будет изменяться анимация. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMyLZA8k7_l1"
      },
      "source": [
        "### [2] Mini-batch SGD\n",
        "\n",
        "Берём несколько рандомных наблюдений и ищем градиент по ним! \n",
        "\n",
        "$$ w_t = w_{t-1} - \\eta \\dfrac{1}{m} \\sum_{j=1}^m \\nabla_w L(w_t, x_{i_j}, y_{i_j}) $$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVgOAq-K7_l2"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "w = np.array([0, 0, 0, 0, 0, 1])\n",
        "\n",
        "eta= 0.1 \n",
        "\n",
        "n_iter = 100\n",
        "batch_size = 4\n",
        "loss = np.zeros(n_iter)\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "for i in range(n_iter):\n",
        "    \n",
        "    # Ваш код здесь \n",
        "\n",
        "visualize(X, y, w, loss)\n",
        "plt.clf()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGdrTaYO7_l2"
      },
      "source": [
        "### [2] Momentum SGD\n",
        "\n",
        "Momentum это метод, который помогает стохастическому градиентному спуску сохранять направление движения. Это осуществляется за счёт добавления в выражение дополнительного слагаемого: накопленного за предыдущие шаги градиента с весом $\\alpha$. \n",
        "<br>\n",
        "<br>\n",
        "\n",
        "$$ \\nu_t = \\alpha \\nu_{t-1} + \\eta\\dfrac{1}{m} \\sum_{j=1}^m \\nabla_w L(w_t, x_{i_j}, y_{i_j}) $$\n",
        "$$ w_t = w_{t-1} - \\nu_t$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5UjKUZQ7_l3"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "w = np.array([0, 0, 0, 0, 0, 1])\n",
        "\n",
        "eta = 0.05 \n",
        "alpha = 0.9 \n",
        "nu = np.zeros_like(w)\n",
        "\n",
        "n_iter = 100\n",
        "batch_size = 4\n",
        "loss = np.zeros(n_iter)\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "for i in range(n_iter):\n",
        "    \n",
        "    # Ваш код здесь \n",
        "\n",
        "visualize(X, y, w, loss)\n",
        "plt.clf()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RiG9eZB7_l3"
      },
      "source": [
        "### [2] RMSprop\n",
        "\n",
        "В этом блоке реализуем RMSprop. Эта вариация градиентного спуска позволяет изменять скорость обучения индивидуально для каждого параметра. \n",
        "\n",
        "$$ G_t^j = \\alpha G_{t-1}^j + (1 - \\alpha) g_{tj}^2 $$\n",
        "$$ w_t^j = w_{t-1}^j - \\dfrac{\\eta}{\\sqrt{G_t^j + \\varepsilon}} g_{tj} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQMnZg-87_l4"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "w = np.array([0, 0, 0, 0, 0, 1.])\n",
        "\n",
        "eta = 0.1 \n",
        "alpha = 0.9 \n",
        "g2 = np.zeros_like(w)\n",
        "eps = 1e-8\n",
        "\n",
        "n_iter = 100\n",
        "batch_size = 4\n",
        "loss = np.zeros(n_iter)\n",
        "plt.figure(figsize=(12,5))\n",
        "for i in range(n_iter):\n",
        "\n",
        "    # Ваш код здесь \n",
        "\n",
        "visualize(X, y, w, loss)\n",
        "plt.clf()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1Bv45bO7_l4"
      },
      "source": [
        "Как траектории обучения различных вариаций градиентного спуска различаются между собой? Ожидаемо ли это? Почему? Что нужно сделать, чтобы реализовать Adam? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzFX1l2r7_l5"
      },
      "source": [
        "### [2] За каждую адекватную вариацию\n",
        "\n",
        "Если понравилось реализовывать свои градиентные спуски и ты находишься от них под глубоким впечатлением, я могу накинуть дополнительные баллы за реализацию каждой новой адекватной вариации. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Igchxlon7_l5"
      },
      "outputs": [],
      "source": [
        "# Ваш код здесь "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "HW2_gradient.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGQ-ND-XWPub"
      },
      "source": [
        "# Как научить компьютер читать? \n",
        "\n",
        "В этой тетрадке мы обучим свой собственный word2vec. Делать мы это будем на каком-нибудь не очень большом тексте, который вам предстоит выбрать самому. На выбор есть [несколько сказок](https://github.com/nevmenandr/word2vec-russian-novels/tree/master/vector-school) и других [литературных штук](https://github.com/nevmenandr/word2vec-russian-novels/tree/master/books_before) из школьной программы. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tK1u1bm1WPuc"
      },
      "outputs": [],
      "source": [
        "# Ссылка на выбранное вами произведение\n",
        "# Для примера возьмем Преступление и Наказание\n",
        "url = 'https://raw.githubusercontent.com/nevmenandr/word2vec-russian-novels/master/books_before/CrimeAndPunishment.txt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxsGMQ9XWPud"
      },
      "source": [
        "Спарсим текст из файлика."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ltRBUDlWPud",
        "outputId": "0506e98e-4c50-4d71-ba7f-a6d1c6910108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "смотреть на эти семь лет, как на семь\n",
            "дней. Он даже и не знал того, что новая жизнь не даром же ему достается, что ее надо еще дорого купить, заплатить за нее великим, будущим подвигом...\n",
            "Но тут уж начинается новая история, история постепенного обновления человека, история постепенного перерождения его, постепенного перехода из одного мира в другой, знакомства с новою, доселе совершенно неведомою действительностью. Это могло бы составить тему нового рассказа, - но теперешний рассказ наш окончен.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "resp = requests.get(url)\n",
        "text = resp.text \n",
        "\n",
        "# Последние 500 символов. Аккуратно! Спойлеры!\n",
        "print(text[-500:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6SqKVCYWPue"
      },
      "source": [
        "## 1. Предобработка\n",
        "\n",
        "Теперь нам надо его немного предобработать.  Пусть все слова пишутся с маленькой буквы. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TA-V-NNCWPue"
      },
      "outputs": [],
      "source": [
        "text = text.lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6wmG7fBWPue"
      },
      "source": [
        "Разобьём весь текст на предложения. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_bwGYk9WPue",
        "outputId": "b7c6cd27-e48a-4a5e-cf1a-af0a5437becd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sents = sent_tokenize(text)\n",
        "len(sents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "td3UWZg7WPue",
        "outputId": "4e657c82-b13a-4ea4-ba77-acbe55c748a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'действительно, на его платье и даже в волосах кое-где виднелись прилипшие былинки сена.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "sents[220]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC6m4LrxWPue"
      },
      "source": [
        "Разобьём каждое предложение на отдельные слова."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixxpBk3yWPuf",
        "outputId": "3d37e676-a00d-444c-b718-13c635275d31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['действительно',\n",
              " 'на',\n",
              " 'его',\n",
              " 'платье',\n",
              " 'и',\n",
              " 'даже',\n",
              " 'в',\n",
              " 'волосах',\n",
              " 'кое',\n",
              " 'где',\n",
              " 'виднелись',\n",
              " 'прилипшие',\n",
              " 'былинки',\n",
              " 'сена']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "tokenizer = RegexpTokenizer('\\w+')\n",
        "tokenizer.tokenize(sents[220])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3X7Giy7WPuf",
        "outputId": "699ed392-1126-453b-d2a0-556bc827fb50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['и',\n",
              "  'каждый',\n",
              "  'раз',\n",
              "  'молодой',\n",
              "  'человек',\n",
              "  'проходя',\n",
              "  'мимо',\n",
              "  'чувствовал',\n",
              "  'какое',\n",
              "  'то',\n",
              "  'болезненное',\n",
              "  'и',\n",
              "  'трусливое',\n",
              "  'ощущение',\n",
              "  'которого',\n",
              "  'стыдился',\n",
              "  'и',\n",
              "  'от',\n",
              "  'которого',\n",
              "  'морщился'],\n",
              " ['он',\n",
              "  'был',\n",
              "  'должен',\n",
              "  'кругом',\n",
              "  'хозяйке',\n",
              "  'и',\n",
              "  'боялся',\n",
              "  'с',\n",
              "  'нею',\n",
              "  'встретиться']]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "sents_tokenize = [tokenizer.tokenize(sent) for sent in sents]\n",
        "sents_tokenize[4:6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNYJIfCDWPuf"
      },
      "outputs": [],
      "source": [
        "# Flatten без numpy :) \n",
        "words = [item for sent in  sents_tokenize for item in sent]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOfch3NgWPuf",
        "outputId": "098defd8-aae5-40e9-d66a-d239b924c44a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "173403"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "len(words) # всего слов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paa8IZivWPuf",
        "outputId": "aea0ad81-7bed-4eeb-c18c-60af8a63688f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24925"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "len(set(words)) # уникальных слов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-dCnuzqWPuf"
      },
      "source": [
        "Можно выбросить все стоп-слова. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Z-mAenEIWPuf",
        "outputId": "cb096821-0e88-4e39-bc8d-b7062829e764"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "151"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopwords_ru = stopwords.words('russian') \n",
        "display(len(stopwords_ru))\n",
        "stopwords_ru[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekyvhLS1WPug"
      },
      "outputs": [],
      "source": [
        "sents_tokenize = [[word for word in text_cur if word not in stopwords_ru] for text_cur in sents_tokenize]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4MMxc9uWPug"
      },
      "source": [
        "Слов в корпусе не очень много. Давайте лемматизируем их.  В этом нам поможет библиотека **pymorphy2.**\n",
        "\n",
        "**pymorphy2** — это полноценный морфологический анализатор, целиком написанный на Python. Он также умеет ставить слова в нужную форму (спрягать и склонять). [Документация по pymorphy2.](https://pymorphy2.readthedocs.io/en/latest/)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vTqA-xNXeAf",
        "outputId": "732671d6-48da-4317-8849-6296ce33b116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt>=0.6\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=5fd7d2319b16c9a11e708eca72254aee228d6b35305d153d431cadfbc592a0fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "q51OOgoBWPug",
        "outputId": "141a0267-e5a9-4db6-829a-fb7fa284b1e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'филипп пойти в авеньон и пленить папа'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "text = \"Филипп пошёл в Авеньон и пленил пап!\"\n",
        "tokens = tokenizer.tokenize(text)\n",
        "\n",
        "\" \".join(morph.normal_forms(token)[0] for token in tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E4rcXbKWPug",
        "outputId": "c83782a3-3072-4145-e692-b8c70c41a49a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parse(word='стали', tag=OpencorporaTag('VERB,perf,intr plur,past,indc'), normal_form='стать', score=0.975342, methods_stack=((DictionaryAnalyzer(), 'стали', 945, 4),)),\n",
              " Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn sing,gent'), normal_form='сталь', score=0.010958, methods_stack=((DictionaryAnalyzer(), 'стали', 13, 1),)),\n",
              " Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn plur,nomn'), normal_form='сталь', score=0.005479, methods_stack=((DictionaryAnalyzer(), 'стали', 13, 6),)),\n",
              " Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn sing,datv'), normal_form='сталь', score=0.002739, methods_stack=((DictionaryAnalyzer(), 'стали', 13, 2),)),\n",
              " Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn sing,loct'), normal_form='сталь', score=0.002739, methods_stack=((DictionaryAnalyzer(), 'стали', 13, 5),)),\n",
              " Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn plur,accs'), normal_form='сталь', score=0.002739, methods_stack=((DictionaryAnalyzer(), 'стали', 13, 9),))]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "p = morph.parse('стали')\n",
        "p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRTewpgqWPug"
      },
      "source": [
        "Обработаем все слова из датасета. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Us9vJH5WPug"
      },
      "outputs": [],
      "source": [
        "sents_tokenize = [[morph.normal_forms(word)[0] for word in text_cur] for text_cur in sents_tokenize]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgtH6nhgWPug"
      },
      "outputs": [],
      "source": [
        "# Flatten без numpy :) \n",
        "words = [item for sent in  sents_tokenize for item in sent]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg9wGz66WPug",
        "outputId": "ad086107-6713-410a-b241-93d42101b59b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "93069"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "len(words) # всего слов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YI_U1BYWPug",
        "outputId": "e506d0ba-e639-402d-9e01-3148ac7fe315"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11084"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "len(set(words)) # уникальных слов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMt4FZLYWPug"
      },
      "source": [
        "Хватит обработок! Мы тут не анализом текстов занимаемся, а нейросетками. Если хотите больше предобработки, [можете прочитать этот мануал](https://nbviewer.jupyter.org/github/FUlyankin/hse_texts_do/blob/master/sem_1/texts_sem1.ipynb) об этом.  Давайте построим словарик с частотностями и перейдём к моделированию. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l78qSli-WPuh",
        "outputId": "f8c7915b-cb43-4754-a3f0-83d053ce5f30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('это', 1449),\n",
              " ('всё', 963),\n",
              " ('знать', 630),\n",
              " ('раскольник', 567),\n",
              " ('свой', 549),\n",
              " ('один', 548),\n",
              " ('сказать', 544),\n",
              " ('говорить', 536),\n",
              " ('человек', 501),\n",
              " ('весь', 442),\n",
              " ('стать', 441),\n",
              " ('мочь', 441),\n",
              " ('который', 430),\n",
              " ('сам', 430),\n",
              " ('такой', 395),\n",
              " ('очень', 387),\n",
              " ('какой', 379),\n",
              " ('соня', 379),\n",
              " ('рука', 369),\n",
              " ('петрович', 369)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "word_dict = Counter(words)\n",
        "word_dict.most_common()[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sZOGYPFWPuh",
        "outputId": "5dfae2e0-42db-470f-a2f2-cce5f28e7481"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4768"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "words = word_dict.most_common()\n",
        "len([item for item in words if item[1] >= 3])  # совсем мало :) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2apkO1L7WPuh"
      },
      "source": [
        "## 2. Моделирование\n",
        "\n",
        "__Основные параметры:__\n",
        "\n",
        "* данные должны быть итерируемым объектом \n",
        "* `size` — размер вектора, \n",
        "* `window` — размер окна наблюдения,\n",
        "* `min_count` — мин. частотность слова в корпусе,\n",
        "* `sg` — используемый алгоритм обучения (0 — CBOW, 1 — Skip-gram),\n",
        "* `sample` — порог для downsampling'a высокочастотных слов,\n",
        "* `workers` — количество потоков,\n",
        "* `alpha` — learning rate,\n",
        "* `iter` — количество итераций,\n",
        "* `max_vocab_size` — позволяет выставить ограничение по памяти при создании словаря (т.е. если ограничение привышается, то низкочастотные слова будут выбрасываться). Для сравнения: 10 млн слов = 1Гб RAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_cG2VaiWPuh",
        "outputId": "2cae4a18-bf51-4e04-baa2-6439800c2e25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 23.4 s, sys: 291 ms, total: 23.7 s\n",
            "Wall time: 14.4 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7944448, 9306900)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "%%time \n",
        "from gensim.models.word2vec import Word2Vec\n",
        "\n",
        "# size - размерность векторов, которые мы хотим обучить\n",
        "# window - ширина окна контекста\n",
        "# min_count - если слово встречается реже, для него не учим модель\n",
        "model = Word2Vec(size=100, window=2, min_count=3, workers=4)\n",
        "\n",
        "# строительство словаря, чтобы обучение шло быстрее\n",
        "model.build_vocab(sents_tokenize)\n",
        "\n",
        "# обучение модели \n",
        "# первый аргумент - наша выборка, генератор будет вкидывать в модель наши тексты, пока они не кончатся\n",
        "# второй аргумент - число примеров в выборке \n",
        "# третий аргумент - количество эпох обучения: сколько раз модель пройдётся по всему корпусу текстов\n",
        "model.train(sents_tokenize, total_examples=model.corpus_count, epochs=100)\n",
        "\n",
        "# !NB в ситуации, когда у нас огромный корпус, 100 эпох это слишком много! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBwKM5khWPuh",
        "outputId": "b87d9fb8-5834-4347-a4fb-70a487d5f6ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13565"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "model.corpus_count # число примеров в обучающей выборке"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-GnyUxNWPuh"
      },
      "source": [
        "Смотрим, сколько в модели слов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRrrszJLWPuh",
        "outputId": "7e19068b-543a-4047-b946-5b47d9fa393e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4768"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "len(model.wv.vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_q5buyAWPuh",
        "outputId": "7db05649-0c0d-4d82-f4bf-91fc7008b0f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "'старуха' in model.wv.vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzHCM0tjWPui"
      },
      "source": [
        "## 3. Свойства модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOWJQG7IWPui",
        "outputId": "c2667691-132e-46d1-9d45-5f2a06deea18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.8561536 , -1.0795974 , -0.26131397,  0.46300855,  1.6357554 ,\n",
              "       -0.0353207 ,  0.5920026 ,  1.890924  , -0.78100294, -0.46361428],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# вектор слова\n",
        "model.wv['старуха'][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BK9oaGjhWPui",
        "outputId": "e5b034b5-4668-4d8c-a3e6-d5b20a1312d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# размерность вектора\n",
        "model.wv['старуха'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zc4Cgy8WPui",
        "outputId": "4e4f7530-25d8-4678-f7d2-80cd218235bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.055715106"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# похожести слов \n",
        "model.wv.similarity('тварь', 'право')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq6s7e-gWPui",
        "outputId": "5dfaee29-e116-4366-e4b5-2698d2be3084"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4192768"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "model.wv.similarity('старуха', 'топор')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqP19kdTWPui",
        "outputId": "d555dc8f-990c-4b3c-b429-68b30185d0cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.99999994"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "model.wv.similarity('тварь', 'тварь')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd4oK3X4WPui",
        "outputId": "aea1ad64-dfdd-4936-c833-81a697d9ca45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('лизавета', 0.5559487342834473),\n",
              " ('обыск', 0.47559523582458496),\n",
              " ('близко', 0.4377446472644806),\n",
              " ('топор', 0.41927677392959595),\n",
              " ('наклепать', 0.41877609491348267),\n",
              " ('отметка', 0.3899194002151489),\n",
              " ('кулак', 0.38478708267211914),\n",
              " ('обратно', 0.3828233480453491),\n",
              " ('домой', 0.37311479449272156),\n",
              " ('ограбить', 0.3721403479576111)]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# самые похожие\n",
        "model.wv.most_similar('старуха')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqfLgU1GWPui",
        "outputId": "960c62ae-1f14-4d51-a8cd-cd8bd9e78e21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ступенька', 0.5415230989456177),\n",
              " ('всходить', 0.5337059497833252),\n",
              " ('прихожая', 0.5223307609558105),\n",
              " ('узенький', 0.4729374647140503),\n",
              " ('ступень', 0.4559502601623535),\n",
              " ('спускаться', 0.45580971240997314),\n",
              " ('коридор', 0.44950059056282043),\n",
              " ('настежь', 0.44040998816490173),\n",
              " ('дворницкий', 0.43754225969314575),\n",
              " ('вниз', 0.4349845349788666)]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "model.wv.most_similar('лестница')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btOfydiqWPui",
        "outputId": "e46c14ef-963f-4b3b-ad85-dd7d3ca4bcf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-2a6704991cd2>:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  model.most_similar(positive=['раскольников'], negative=['тварь'])[:10]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('несколько', 0.3556216359138489),\n",
              " ('пристально', 0.2935299575328827),\n",
              " ('почтительно', 0.29252225160598755),\n",
              " ('прислушиваться', 0.2689328193664551),\n",
              " ('незнакомый', 0.26657626032829285),\n",
              " ('довольно', 0.2604427933692932),\n",
              " ('замешкаться', 0.2600513696670532),\n",
              " ('край', 0.2588003873825073),\n",
              " ('слушать', 0.253754198551178),\n",
              " ('казённый', 0.2519662380218506)]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# арифметика\n",
        "model.most_similar(positive=['раскольников'], negative=['тварь'])[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaiElYnqWPui"
      },
      "source": [
        "## 4. Как дообучить модель? \n",
        "\n",
        "Ради чистоты эксперимента сохраним текущую модель и заново подгрузим её. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNliEBUrWPui"
      },
      "outputs": [],
      "source": [
        "model_path = \"./our_w2v.model\"\n",
        "model.save(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-ATkaDTWPuj"
      },
      "outputs": [],
      "source": [
        "our_model = Word2Vec.load(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpWZvsFdWPuj"
      },
      "source": [
        "Подгрузим другое произведение и сделаем для него предобработку. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIY0paoYWPuj",
        "outputId": "b62564c0-b761-40a7-b3c1-2f43a4757856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " узнает...\n",
            "В нем взыграло ретивое!\n",
            "\"Что я вижу? что такое?\n",
            "Как!\" - и дух в нем занялся...\n",
            "Царь слезами залился,\n",
            "Обнимает он царицу,\n",
            "И сынка, и молодицу,\n",
            "\n",
            "\n",
            "\n",
            "И садятся все за стол;\n",
            "И веселый пир пошел.\n",
            "А ткачиха с поварихой,\n",
            "С сватьей бабой Бабарихой\n",
            "Разбежались по углам;\n",
            "Их нашли насилу там.\n",
            "Тут во всем они признались,\n",
            "Повинились, разрыдались;\n",
            "Царь для радости такой\n",
            "Отпустил всех трех домой.\n",
            "День прошел - царя Салтана\n",
            "Уложили спать вполпьяна.\n",
            "Я там был; мед, пиво пил -\n",
            "И усы лишь обмочил.\n",
            "\n",
            "1831\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "url = 'https://raw.githubusercontent.com/nevmenandr/word2vec-russian-novels/master/vector-school/SkazkaOCareSaltane.txt'\n",
        "\n",
        "resp = requests.get(url)\n",
        "text2 = resp.text \n",
        "\n",
        "# Последние 500 символов. Аккуратно! Спойлеры!\n",
        "print(text2[-500:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9meag8UWPuj"
      },
      "source": [
        "Предобработка."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtCuPrW7WPuj"
      },
      "outputs": [],
      "source": [
        "text2 = text2.lower()\n",
        "sents2 = sent_tokenize(text2)\n",
        "\n",
        "sents_tokenize2 = [tokenizer.tokenize(sent) for sent in sents2]\n",
        "sents_tokenize2 = [[morph.normal_forms(word)[0] for word in text_cur if word not in stopwords_ru]\n",
        "                      for text_cur in sents_tokenize2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKN8oXsOWPuj",
        "outputId": "c73e8f6e-e853-4553-e867-92ed864feaae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['сени', 'выйти', 'царь', 'отец']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "sents_tokenize2[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aIGEICvWPuj",
        "outputId": "ace9dd62-13ea-4aeb-ba72-3fa06a68b9f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "254"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "len(sents_tokenize2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3KnXD17WPuj"
      },
      "source": [
        "Дополняем модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60QhZ-OLWPuj",
        "outputId": "55a65148-ac95-474c-a056-8854731710d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(177498, 269000)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# обновили словарь\n",
        "our_model.build_vocab(sents_tokenize2, update=True)\n",
        "\n",
        "# дообучили\n",
        "our_model.train(sents_tokenize2, total_examples=our_model.corpus_count, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sqa8_SoWPuj",
        "outputId": "fd5a066d-b784-48fc-d454-92b6935c60ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "'ядро' in model.wv.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7NQGIvQWPuj",
        "outputId": "3545c06f-c213-43cc-dbf7-b542f9cef167"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "'ядро' in our_model.wv.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quARKMR-WPuj",
        "outputId": "998e603b-b871-44dc-ed37-ae5869fbfdbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('изумруд', 0.7330085039138794),\n",
              " ('скатерть', 0.6428670883178711),\n",
              " ('грызть', 0.6196736097335815),\n",
              " ('чистый', 0.6063417196273804),\n",
              " ('складка', 0.5761065483093262),\n",
              " ('шкатулка', 0.5548331141471863),\n",
              " ('серебро', 0.546135425567627),\n",
              " ('пристань', 0.5433902740478516),\n",
              " ('орешек', 0.5368527770042419),\n",
              " ('золотой', 0.5324065089225769)]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "our_model.wv.most_similar('ядро')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt4evqv0WPuj"
      },
      "source": [
        "Пример со старым словом."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AsLlqZJWPuk",
        "outputId": "9da33ba2-640a-4716-d33e-44caff4deeae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('обеспечить', 0.5876461267471313),\n",
              " ('губерния', 0.4981480836868286),\n",
              " ('благословить', 0.48843833804130554),\n",
              " ('секрет', 0.4776530861854553),\n",
              " ('враньё', 0.45808500051498413),\n",
              " ('воровать', 0.45804673433303833),\n",
              " ('раздражать', 0.45562446117401123),\n",
              " ('наущение', 0.4550246000289917),\n",
              " ('расспрос', 0.44552212953567505),\n",
              " ('приём', 0.4437122344970703)]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "our_model.wv.most_similar('сын')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOUyZtXTWPuk",
        "outputId": "8c1bb9e2-dd2a-48d3-de81-7765f66ac223"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('обеспечить', 0.5480742454528809),\n",
              " ('наущение', 0.498038649559021),\n",
              " ('секрет', 0.48968130350112915),\n",
              " ('преувеличить', 0.4833449721336365),\n",
              " ('раздражать', 0.48290401697158813),\n",
              " ('приём', 0.46065837144851685),\n",
              " ('посредство', 0.45348575711250305),\n",
              " ('следить', 0.45188313722610474),\n",
              " ('выздоровление', 0.4381413459777832),\n",
              " ('родственница', 0.4327961802482605)]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "model.wv.most_similar('сын')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fHlOmKlbbWmn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}